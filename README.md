# Toxic_Comment_Classification_Bert.ipynb


# Toxic Comment Classification with BERT

This repository implements a multiâ€label toxic comment classifier based on fineâ€tuning BERT.  
Given an input comment, the model predicts six toxicity subtypes: **toxic**, **severe toxic**, **obscene**, **threat**, **insult**, and **identity hate**.

---

## ğŸ“– Table of Contents

1. [Background](#background)  
2. [Features](#features)  
3. [Data](#data)  
4. [Installation & Requirements](#installation--requirements)  
5. [Usage](#usage)  
6. [Notebook Overview](#notebook-overview)  
7. [Results](#results)  
8. [Citations](#citations)  

---

## ğŸ§ Background

Automated moderation systems must contend with subtle, context-dependent toxicity in text.  
This notebook fineâ€tunes a pre-trained BERT (bert-base-uncased) model on the **Wikipedia Toxicity Subtypes** dataset, which contains âˆ¼127 K comments annotated for six toxicity labels.

---

## âœ¨ Features

- **Multiâ€label classification** over six toxicity subtypes  
- **Data preprocessing** with the BERT tokenizer (max length 128)  
- **Fine-tuning** using AdamW, binary cross-entropy loss, 3 epochs, batch size 32, LR = 2Ã—10â»âµ  
- **Training dynamics logging** (loss every 100 steps â†’ `training_log.xlsx`)  
- **Inference & export** of perâ€comment probabilities and binary predictions to `test_predicted.csv`  
- **Evaluation metrics**: perâ€label ROC-AUC, macro-averaged F1, overall accuracy  

---

## ğŸ“‚ Data

We use the **Wikipedia Toxicity Subtypes** split as follows:

| Split       | Samples  |
| ----------- | -------- |
| Training    | 102 256  |
| Validation  | 12 564   |
| Test        | 12 564   |
| Held-out    | 999      |

Download `train.csv`, `dev.csv`, `test.csv`, and `test_public_expanded.csv` from the [Kaggle Jigsaw Toxic Comment challenge](https://kaggle.com/competitions/jigsaw-toxic-comment-classification-challenge) and place them in a `data/` folder.

---

## âš™ï¸ Installation & Requirements

1. **Clone the repo**  
   ```bash
   git clone https://github.com/<your-username>/toxic-comment-bert.git
   cd toxic-comment-bert


ğŸ““ Notebook Overview
Setup â€“ imports, device check

Data Loading â€“ CSV â†’ datasets

Preprocessing â€“ BERT tokenization

Model Definition â€“ BertForSequenceClassification with 6 outputs

Training Loop â€“ AdamW, BCE loss, logging

Validation â€“ compute F1 & ROC-AUC per epoch

Test Inference â€“ export predictions to CSV

Metrics & Analysis â€“ final Accuracy, Macro-F1, ROC-AUC

Gradio Demo (optional)

ğŸ“ˆ Results
Test Accuracy: 0.9123

Macro-F1: 0.9075

Macro-ROC-AUC: 0.9621

ğŸ“š Citations
If you use this work, please cite:

N. Rani, â€œFine-Tuning Large Language Models Using NLP Techniques for Enhanced Bias Mitigation in Generative AI,â€ M.Tech project report, IIT Jodhpur, 2025.

And for the dataset:

cjadams et al., â€œToxic comment classification challenge,â€ Kaggle, 2017.
