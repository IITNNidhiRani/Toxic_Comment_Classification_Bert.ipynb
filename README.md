
# Toxic Comment Classification with BERT

This repository implements a multi‚Äêlabel toxic comment classifier based on fine‚Äêtuning BERT.  
Given an input comment, the model predicts six toxicity subtypes: **toxic**, **severe toxic**, **obscene**, **threat**, **insult**, and **identity hate**.

---

##  Table of Contents

1. [Background](#background)  
2. [Features](#features)  
3. [Data](#data)  
4. [Installation & Requirements](#installation--requirements)  
5. [Usage](#usage)  
6. [Notebook Overview](#notebook-overview)  
7. [Results](#results)  
8. [Citations](#citations)  

---

## Background

Automated moderation systems must contend with subtle, context-dependent toxicity in text.  
This notebook fine‚Äêtunes a pre-trained BERT (bert-base-uncased) model on the **Wikipedia Toxicity Subtypes** dataset, which contains ‚àº127 K comments annotated for six toxicity labels.

---

##  Features

- **Multi‚Äêlabel classification** over six toxicity subtypes  
- **Data preprocessing** with the BERT tokenizer (max length 128)  
- **Fine-tuning** using AdamW, binary cross-entropy loss, 3 epochs, batch size 32, LR = 2√ó10‚Åª‚Åµ  
- **Training dynamics logging** (loss every 100 steps ‚Üí `training_log.xlsx`)  
- **Inference & export** of per‚Äêcomment probabilities and binary predictions to `test_predicted.csv`  
- **Evaluation metrics**: per‚Äêlabel ROC-AUC, macro-averaged F1, overall accuracy  

---

## Data

We use the **Wikipedia Toxicity Subtypes** split as follows:

| Split       | Samples  |
| ----------- | -------- |
| Training    | 102 256  |
| Validation  | 12 564   |
| Test        | 12 564   |
| Held-out    | 999      |

Download `train.csv`, `dev.csv`, `test.csv`, and `test_public_expanded.csv` from the [Kaggle Jigsaw Toxic Comment challenge](https://kaggle.com/competitions/jigsaw-toxic-comment-classification-challenge) and place them in a `data/` folder.

---



üìì Notebook Overview
Setup ‚Äì imports, device check

Data Loading ‚Äì CSV ‚Üí datasets

Preprocessing ‚Äì BERT tokenization

Model Definition ‚Äì BertForSequenceClassification with 6 outputs

Training Loop ‚Äì AdamW, BCE loss, logging

Validation ‚Äì compute F1 & ROC-AUC per epoch

Test Inference ‚Äì export predictions to CSV

Metrics & Analysis ‚Äì final Accuracy, Macro-F1, ROC-AUC

Gradio Demo (optional)

üìà Results
Test Accuracy: 0.9123

Macro-F1: 0.9075

Macro-ROC-AUC: 0.9621

Citations
If you use this work, please cite:

N. Rani, ‚ÄúFine-Tuning Large Language Models Using NLP Techniques for Enhanced Bias Mitigation in Generative AI,‚Äù M.Tech project report, IIT Jodhpur, 2025.

And for the dataset:

1. Wikipedia Toxicity Subtypes (Text)
‚Ä¢ Comments from Wikipedia annotated for toxicity types.
‚Ä¢ Human-labeled, split: ~80% train, 10% val, 10% test.
‚Ä¢https://www.kaggle.com/competitions/jigsaw-toxic-comment-classification-challenge/data
